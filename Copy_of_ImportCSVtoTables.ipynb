{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ImportCSVtoTables",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpZG9HlMbB6Z"
      },
      "outputs": [],
      "source": [
        "\"\"\"Create Project\"\"\"\n",
        "\"\"\"Create instance\"\"\"\n",
        "\"\"\"Create database inside instance\"\"\"\n",
        "\"\"\"create Google Cloud Storage bucket for your project\"\"\"\n",
        "\"\"\"Write SQL to create tables and save as txt in your project bucket\"\"\"\n",
        "\"\"\"** add data to your SQL to test\"\"\" \n",
        "\"\"\"Install mysql.connector\"\"\"\n",
        "\"\"\"https://www.dataquest.io/blog/sql-insert-tutorial/\"\"\"\n",
        "!pip install mysql.connector\n",
        "!curl ipecho.net/plain  # look at your ip address for your jupyter notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Connect to DB\"\"\"\n",
        "\"\"\"First add your ip address to authorized networks\"\"\"\n",
        "\"\"\"code to get google colab ip address to add to authorized networks\"\"\"\n",
        "\n",
        "# # This may take a couple minutes\n",
        "import mysql.connector\n",
        "\n",
        "mydbname = 'whateveryoulike'\n",
        "gc_ip = \"00.000.00.000\"\n",
        "password_root = '123456'\n",
        "root_db = 'mydb'\n",
        "\n",
        "my_connect = mysql.connector.connect(\n",
        "  host=gc_ip,  # change this with your google cloud address\n",
        "  user=\"root\",\n",
        "  passwd= password_root, # your password here\n",
        "  database=root_db # database name\n",
        ")\n",
        "####### end of connection details ####\n",
        "my_cursor = my_connect.cursor()\n",
        "\n",
        "# my_cursor.execute(\"SELECT * FROM amzbiz\") # table name\n",
        "\n",
        "# my_result = my_cursor.fetchone()\n",
        "# while my_result is not None:\n",
        "#     print(my_result)\n",
        "#     my_result = my_cursor.fetchone()\n",
        "\n",
        "my_cursor.execute(f\"DROP TABLE {mydbname}\")  # clear out database\n"
      ],
      "metadata": {
        "id": "8KDsmi9otyI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pymysql\n",
        "from sqlalchemy import create_engine\n",
        "import mysql.connector\n",
        "!pip install pymysql\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "my_connect = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
        "                       .format(user=\"root\",\n",
        "                               host=gc_ip,  # your google cloud address\n",
        "                               pw=password_root,  # your password here\n",
        "                               db=root_db))  # database name\n",
        "\n",
        "\n",
        "\"\"\"Read in google drive data\"\"\"\n",
        "\"\"\"Mount google drive folders to google colab\"\"\"\n",
        "\"\"\"if  you did not create the folder, add a shortcut to your drive\"\"\"\n",
        "\n",
        "directory = '/content/drive/My Drive/Your Folder'\n",
        "folders = ['select folders if you want']  \n",
        "ogdf = pd.DataFrame()\n",
        "\n",
        "for f in folders:\n",
        "    for root,dirs,files in os.walk(f'{directory}/{f}'):\n",
        "        for file in files:\n",
        "            if file.endswith('.csv'):\n",
        "                # print(year, file)\n",
        "                temp = pd.read_csv(f'{directory}/{f}/{file}')\n",
        "                temp['date'] = file.replace('.csv', '')\n",
        "                ogdf = ogdf.append(temp, ignore_index=True)\n",
        "                \n",
        "ogdf['date']= pd.to_datetime(ogdf['date'], errors='coerce')  # change your date to a date!\n",
        "ogdf.sort_values('date', ascending=False, inplace=True)\n",
        "\n",
        "\n",
        "pricecol = [ 'column names that are prices']  # must be changed to float\n",
        "percol = ['column names that are percentages'] # must be changed to float\n",
        "\n",
        "ogdf[pricecol] = ogdf[pricecol].apply(lambda x: x.str.replace('$',''))\n",
        "ogdf[percol] = ogdf[percol].apply(lambda x: x.str.replace('%',''))\n",
        "\n",
        "\n",
        "ogdf = ogdf.replace({',': ''} , regex=True)\n",
        "ogdf[pricecol] = ogdf[pricecol].astype(float)\n",
        "ogdf = ogdf.fillna(0) \n",
        "ogdf[percol] = ogdf[percol].astype(float)*.01  # change to decimal\n",
        "\n",
        "\n",
        "# First create ogdf :)\n",
        "ogdf.to_sql(mydbname, con = my_connect, if_exists = 'append', index=False)  # name the database or append if it already exists\n",
        "\n",
        "display(len(ogdf))\n",
        "display(ogdf.tail(1))\n"
      ],
      "metadata": {
        "id": "44pdYvITJvRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HcVN5BAwyaf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QYwYGfmC2E1n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}